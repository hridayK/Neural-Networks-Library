{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nnl import bundle as nn\n",
    "import keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "fashion_mnist_labels = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = []\n",
    "X_train1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(X_train)):\n",
    "    X_train1.append(np.reshape(X_train[i],(784)))\n",
    "\n",
    "for i in range(0,len(X_test)):\n",
    "    X_test1.append(np.reshape(X_test[i],(784)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (60000, 784))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1 = np.array(X_train1)\n",
    "X_test1 = np.array(X_test1)\n",
    "\n",
    "\"\"\"\n",
    "X_test1 = []\n",
    "X_train1 = []\n",
    "\n",
    "for i in range(0,len(X_train)):\n",
    "    X_train1.append(np.reshape(X_train[i],(784)))\n",
    "\n",
    "for i in range(0,len(X_test)):\n",
    "    X_test1.append(np.reshape(X_test[i],(784)))\n",
    "    \n",
    "X_train1 = np.array(X_train1)\n",
    "X_test1 = np.array(X_test1)\n",
    "\"\"\"\n",
    "X_test1.shape, X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "training, acc: 0.925, loss: 0.247 (data_loss: 0.247, reg_loss: 0.000), lr: 0.000681198910081744\n",
      "\n",
      "epoch: 1\n",
      "training, acc: 0.971, loss: 0.096 (data_loss: 0.096, reg_loss: 0.000), lr: 0.0005162622612287042\n",
      "\n",
      "epoch: 2\n",
      "training, acc: 0.981, loss: 0.062 (data_loss: 0.062, reg_loss: 0.000), lr: 0.0004156275976724854\n",
      "\n",
      "epoch: 3\n",
      "training, acc: 0.988, loss: 0.039 (data_loss: 0.039, reg_loss: 0.000), lr: 0.00034782608695652176\n",
      "\n",
      "epoch: 4\n",
      "training, acc: 0.992, loss: 0.027 (data_loss: 0.027, reg_loss: 0.000), lr: 0.0002990430622009569\n",
      "\n",
      "epoch: 5\n",
      "training, acc: 0.995, loss: 0.019 (data_loss: 0.019, reg_loss: 0.000), lr: 0.00026226068712300026\n",
      "\n",
      "epoch: 6\n",
      "training, acc: 0.996, loss: 0.014 (data_loss: 0.014, reg_loss: 0.000), lr: 0.00023353573096683791\n",
      "\n",
      "epoch: 7\n",
      "training, acc: 0.997, loss: 0.010 (data_loss: 0.010, reg_loss: 0.000), lr: 0.00021048200378867611\n",
      "\n",
      "epoch: 8\n",
      "training, acc: 0.998, loss: 0.007 (data_loss: 0.007, reg_loss: 0.000), lr: 0.00019157088122605365\n",
      "\n",
      "epoch: 9\n",
      "training, acc: 0.999, loss: 0.005 (data_loss: 0.005, reg_loss: 0.000), lr: 0.00017577781683951485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = nn.Model()\n",
    "\n",
    "\n",
    "# Add layers\n",
    "model.add(nn.layer_dense(784, 128))\n",
    "model.add(nn.relu())\n",
    "model.add(nn.layer_dense(128, 128))\n",
    "model.add(nn.relu())\n",
    "model.add(nn.layer_dense(128, 10))\n",
    "model.add(nn.softmax())\n",
    "\n",
    "# Set loss, optimizer and accuracy objects\n",
    "model.set(\n",
    "    loss=nn.loss_categoricalCrossentropy(),\n",
    "    optimizer=nn.optimizer_adam(decay=1e-3),\n",
    "    accuracy=nn.accuracy_categorical()\n",
    ")\n",
    "\n",
    "# Finalize the model\n",
    "model.finalize()\n",
    "\n",
    "# Train the model\n",
    "model.train(X_train1, y_train, validation_data=(X_test1, y_test),\n",
    "            epochs=10, batch_size=128, print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input given is an image of: Ankle boot\n",
      "The model predicted it to be a: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "test_input = fashion_mnist_labels[y_test[9]]\n",
    "model_prediction = fashion_mnist_labels[np.argmax(model.predict(X_test1[9]))]\n",
    "print(f'Test input given is an image of: {test_input}')\n",
    "print(f'The model predicted it to be a: {model_prediction}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
